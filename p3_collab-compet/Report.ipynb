{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition Project Report\n",
    "\n",
    "---\n",
    "\n",
    "### 1.Examination of State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1. If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01. Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Each agent receives its own, local observation. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping.\n",
    "\n",
    "The task is episodic, and in order to solve the environment, your agents must get an average score of +0.5 (over 100 consecutive episodes, after taking the maximum over both agents). Specifically,\n",
    "\n",
    "After each episode, we add up the rewards that each agent received (without discounting), to get a score for each agent. This yields 2 (potentially different) scores. We then take the maximum of these 2 scores.\n",
    "This yields a single score for each episode.\n",
    "The environment is considered solved, when the average (over 100 episodes) of those scores is at least +0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Algorithm\n",
    "\n",
    "Algorithm is DDPG. DDPG algorithm uses two seperate network which are working collaboratively; actor and critic. Actor network does policiy approximation where critic does value estimation. Training of this network composed out of two steps; acting and learning. In acting step, agent gives state vector as an input to Actor network and receives actions to be taken. In learning step, Critic network evaluates correctness of action taken and gives feed to Actor network so Actor network adjust its weights accordingly.\n",
    "\n",
    "DDPG is used for multi-agent system. It is adapted to simultaneously train both agents through self-play. Each agent used the same actor network to select actions, and the experience was added to a shared replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Actor, Critic\n",
    "from agent import Agent\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from collections import namedtuple, deque\n",
    "from typing import NamedTuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(NamedTuple):\n",
    "    num_workers: int = 2\n",
    "    episode_count: int = 10000\n",
    "    buffer_size = int(1e5)  \n",
    "    mini_batch_size: int = 1024\n",
    "        \n",
    "class DeviceConfig:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DeviceConfig.device = device\n",
    "\n",
    "config = Config(num_workers=num_agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Networks\n",
    "\n",
    "#### Actor Network\n",
    "\n",
    "input size = 24 output size = 2. One hidden layers and one output layer each hidden layer has 256 hidden units and is followed by a ReLU activation layer. A batch normalization layer after the first layer Output layer is followed by a tanh activation layer\n",
    "\n",
    "#### Critic Network\n",
    "\n",
    "input size = 33 output size = 1. One hidden layers and one output layer each hidden layer has 256 hidden units and is followed by a ReLU activation layer A batch normalization layer after the first layer. Output layer is followed no activation unit\n",
    "\n",
    "#### Hyperparameters\n",
    "\n",
    "Mini batch size = 1024\n",
    "Tau = 0.001\n",
    "Gamma = 0.99\n",
    "Learning rate of actor = 0.001\n",
    "Learning rate of critic = 0.001\n",
    "Weight decay = 0\n",
    "Epsilon minimum = 0.1\n",
    "Epsilon maximum = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg(agent, max_step=10000, train_mode=True):\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = []\n",
    "        \n",
    "    for i in range(1, config.episode_count+1):\n",
    "        begin = time.time()\n",
    "        \n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        scores_run = np.zeros(num_agents)\n",
    "\n",
    "        for t in range(max_step): \n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations \n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            if train_mode:\n",
    "                agent.step(states, actions, rewards, next_states, dones)\n",
    "\n",
    "            states = next_states\n",
    "            scores_run += rewards \n",
    "            if np.any(dones):\n",
    "                break\n",
    "\n",
    "        score = np.mean(scores_run)\n",
    "\n",
    "        scores_window.append(score)\n",
    "        score_average = np.mean(scores_window)\n",
    "        scores.append(score)\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            print('\\rEpisode {} Average score: {:.2f} Min: {:.2f} Max: {:.2f} Time: {:.2f} Epsilon: {:.2f}'.format(\n",
    "                i, \n",
    "                score_average, \n",
    "                np.min(scores), \n",
    "                np.max(scores), \n",
    "                time.time() - begin,\n",
    "                agent.epsilon\n",
    "            ))        \n",
    "                    \n",
    "        if score_average >= 0.5:\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            print('\\nSolve in {:d} episodes. Average score: {:.2f}'.format(i, score_average))            \n",
    "            break            \n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.36 Epsilon: 1.00\n",
      "Episode 100 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.37 Epsilon: 1.00\n",
      "Episode 150 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.36 Epsilon: 1.00\n",
      "Episode 200 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.37 Epsilon: 1.00\n",
      "Episode 250 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.36 Epsilon: 1.00\n",
      "Episode 300 Average score: 0.00 Min: -0.00 Max: 0.05 Time: 1.04 Epsilon: 1.00\n",
      "Episode 350 Average score: 0.00 Min: -0.00 Max: 0.05 Time: 0.37 Epsilon: 1.00\n",
      "Episode 400 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.37 Epsilon: 1.00\n",
      "Episode 450 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.36 Epsilon: 1.00\n",
      "Episode 500 Average score: -0.00 Min: -0.00 Max: 0.05 Time: 0.37 Epsilon: 1.00\n",
      "Episode 550 Average score: -0.00 Min: -0.00 Max: 0.15 Time: 0.37 Epsilon: 1.00\n",
      "Episode 600 Average score: 0.00 Min: -0.00 Max: 0.15 Time: 0.37 Epsilon: 1.00\n",
      "Episode 650 Average score: 0.01 Min: -0.00 Max: 0.15 Time: 1.06 Epsilon: 1.00\n",
      "Episode 700 Average score: 0.01 Min: -0.00 Max: 0.15 Time: 1.07 Epsilon: 1.00\n",
      "Episode 750 Average score: 0.01 Min: -0.00 Max: 0.15 Time: 0.69 Epsilon: 1.00\n",
      "Episode 800 Average score: 0.01 Min: -0.00 Max: 0.15 Time: 0.70 Epsilon: 1.00\n",
      "Episode 850 Average score: 0.02 Min: -0.00 Max: 0.15 Time: 0.38 Epsilon: 1.00\n",
      "Episode 900 Average score: 0.01 Min: -0.00 Max: 0.15 Time: 0.37 Epsilon: 1.00\n",
      "Episode 950 Average score: 0.00 Min: -0.00 Max: 0.15 Time: 0.37 Epsilon: 1.00\n",
      "Episode 1000 Average score: 0.00 Min: -0.00 Max: 0.15 Time: 1.08 Epsilon: 1.00\n",
      "Episode 1050 Average score: 0.00 Min: -0.00 Max: 0.15 Time: 0.39 Epsilon: 1.00\n",
      "Episode 1100 Average score: 0.01 Min: -0.01 Max: 0.15 Time: 1.08 Epsilon: 1.00\n",
      "Episode 1150 Average score: 0.02 Min: -0.01 Max: 0.15 Time: 0.69 Epsilon: 1.00\n",
      "Episode 1200 Average score: 0.03 Min: -0.01 Max: 0.15 Time: 1.09 Epsilon: 1.00\n",
      "Episode 1250 Average score: 0.03 Min: -0.01 Max: 0.25 Time: 0.73 Epsilon: 1.00\n",
      "Episode 1300 Average score: 0.02 Min: -0.01 Max: 0.25 Time: 0.38 Epsilon: 1.00\n",
      "Episode 1350 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 0.38 Epsilon: 1.00\n",
      "Episode 1400 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 1.12 Epsilon: 1.00\n",
      "Episode 1450 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 0.38 Epsilon: 1.00\n",
      "Episode 1500 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 0.38 Epsilon: 1.00\n",
      "Episode 1550 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 0.73 Epsilon: 1.00\n",
      "Episode 1600 Average score: 0.01 Min: -0.01 Max: 0.25 Time: 0.70 Epsilon: 1.00\n",
      "Episode 1650 Average score: 0.04 Min: -0.01 Max: 0.25 Time: 0.74 Epsilon: 1.00\n",
      "Episode 1700 Average score: 0.05 Min: -0.01 Max: 0.25 Time: 1.11 Epsilon: 1.00\n",
      "Episode 1750 Average score: 0.06 Min: -0.01 Max: 0.30 Time: 1.86 Epsilon: 1.00\n",
      "Episode 1800 Average score: 0.08 Min: -0.01 Max: 0.30 Time: 2.93 Epsilon: 1.00\n",
      "Episode 1850 Average score: 0.07 Min: -0.01 Max: 0.30 Time: 0.71 Epsilon: 1.00\n",
      "Episode 1900 Average score: 0.06 Min: -0.01 Max: 0.30 Time: 3.02 Epsilon: 1.00\n",
      "Episode 1950 Average score: 0.07 Min: -0.01 Max: 0.70 Time: 1.13 Epsilon: 1.00\n",
      "Episode 2000 Average score: 0.08 Min: -0.01 Max: 0.70 Time: 4.87 Epsilon: 1.00\n",
      "Episode 2050 Average score: 0.07 Min: -0.01 Max: 0.70 Time: 1.91 Epsilon: 1.00\n",
      "Episode 2100 Average score: 0.11 Min: -0.01 Max: 1.20 Time: 10.37 Epsilon: 1.00\n",
      "Episode 2150 Average score: 0.13 Min: -0.01 Max: 1.20 Time: 5.06 Epsilon: 1.00\n",
      "Episode 2200 Average score: 0.13 Min: -0.01 Max: 1.20 Time: 2.71 Epsilon: 1.00\n",
      "Episode 2250 Average score: 0.12 Min: -0.01 Max: 1.20 Time: 2.74 Epsilon: 1.00\n",
      "Episode 2300 Average score: 0.12 Min: -0.01 Max: 1.20 Time: 1.95 Epsilon: 1.00\n",
      "Episode 2350 Average score: 0.12 Min: -0.01 Max: 1.20 Time: 3.46 Epsilon: 1.00\n",
      "Episode 2400 Average score: 0.16 Min: -0.01 Max: 1.20 Time: 2.31 Epsilon: 1.00\n",
      "Episode 2450 Average score: 0.17 Min: -0.01 Max: 1.20 Time: 2.75 Epsilon: 1.00\n",
      "Episode 2500 Average score: 0.18 Min: -0.01 Max: 1.25 Time: 0.40 Epsilon: 1.00\n",
      "Episode 2550 Average score: 0.23 Min: -0.01 Max: 2.30 Time: 1.93 Epsilon: 1.00\n",
      "Episode 2600 Average score: 0.39 Min: -0.01 Max: 2.60 Time: 1.19 Epsilon: 1.00\n",
      "Episode 2650 Average score: 0.47 Min: -0.01 Max: 2.60 Time: 8.80 Epsilon: 1.00\n",
      "Episode 2700 Average score: 0.43 Min: -0.01 Max: 2.65 Time: 17.83 Epsilon: 1.00\n",
      "Episode 2750 Average score: 0.43 Min: -0.01 Max: 2.65 Time: 1.18 Epsilon: 1.00\n",
      "Episode 2800 Average score: 0.33 Min: -0.01 Max: 2.65 Time: 0.40 Epsilon: 1.00\n",
      "Episode 2850 Average score: 0.27 Min: -0.01 Max: 2.65 Time: 2.29 Epsilon: 1.00\n",
      "Episode 2900 Average score: 0.42 Min: -0.01 Max: 2.65 Time: 2.33 Epsilon: 1.00\n",
      "Episode 2950 Average score: 0.44 Min: -0.01 Max: 2.65 Time: 38.97 Epsilon: 1.00\n",
      "\n",
      "Solve in 2966 episodes. Average score: 0.50\n"
     ]
    }
   ],
   "source": [
    "rand_seed = 0\n",
    "agent = Agent(config=config,\n",
    "              state_size=state_size, \n",
    "              action_size=action_size, \n",
    "              num_agents=num_agents, \n",
    "              random_seed=rand_seed,\n",
    "              device=device)\n",
    "\n",
    "scores = ddpg(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot of Rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAESCAYAAADXMlMiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcFPWd//HXZwaG+xABwSiiYpSoERVjVCTGY2N0k/zWxGQTTWIuV81tNOrqRnN4xFXiEY817i5q4iZBTaLxQAFFg6gMKoKCct8wBwxz39/fH1Uz1PR0T3dPV3dXz7yfj0c/6K76VtW3uob69Peo79ecc4iIiPRWUb4zICIihU2BREREMqJAIiIiGVEgERGRjCiQiIhIRhRIREQkIwokIiKSEQUSERHJiAKJiIhkZEC+M5AtY8eOdZMnT853NkRECsrSpUsrnHPj0tmmzwaSyZMnU1pamu9siIgUFDPbmO42qtoSEZGMKJCIiEhGFEhERCQjCiQiIpIRBRIREcmIAomIiGREgURERDKiQCIikiXOOR5fuoWG5rasH6u1rZ0/L9lMW3vup09XIBERyZJFayr5yZxl3PTMyqwfa/arG/jp4+/w6Bubsn6sWAokIiJZsqu+ucu/2bTbP8aeHBwrlgKJiEiWNLe2AzCouG/favv22YmIhOTel9bwpyVdq43mr9zJL556L+E2HYGkZIB3q33wlXWcOWsh//2P9Skf1znHlXOW8cb6Xfz1ra3MeuGDuOnueXEtALc9/wGL1lSkvP8wKJCIiKTg1ufe56rHl3dZ9q2HSvmfRYmDQpvzGr6LiwyAXz29kjVltfzy74mDT6zmtnbmLN3ChQ++zo/+9DZ3zV+ddJsLHnw95f2HQYFEREQyokAiIiIZyVkgMbNrzGyJmVWbWbmZPWVmRyXZZrKZuTivs3OVbxGRoK/+9+sccs3Toe7z6Bvmct69i3pM48j98yGpymWJ5DTgXuBk4HSgFZhnZmNS2PZsYGLgtSBLeRQR6dErqysI+5m/msZW3txUFXedYeEeLAtyNkOic+5Twc9m9lVgD3AK8FSSzSudczuylTcREem9fLaRjPCPvzuFtE+YWZmZLTKzL2Q5XyIi4XDhFV162lXphl2hHac38hlI7gTeBhb3kKYWuAL4InAOMB/4k5ldGC+xmV1sZqVmVlpeXh52fkVEesWyWDu1YNVOvnB/T7fR7MtZ1VaQmc0CZgAznHMJRzNzzlUAtwcWlZrZWOCnwO/jpH8AeABg+vTp0W2ZEhFJU6JgtGV3Q24zEkfOSyRm9hvgy8Dpzrl1vdjF68Bh4eZKRCTaQqwlC11OSyRmdifwr8BpzrlVvdzNNGB7eLkSEYmubFaLhSWXz5HcA3wDrzSy28wm+K/hgTQ3m9n8wOevm9lXzGyqmR1uZlcA3wXuzlW+RUSi5u/vbMt3FrrIZdXWZXg9tebjlSg6XlcE0kwEDo3Z7jqgFFiCV5r5pnPuN1nPrYhIRK3cXp3vLHSRy+dIkhbQnHMXxXx+CHgoW3kSEcmmMJs1ItxEorG2RESyLZOn0+M1sket4V2BRESkAES5zV2BRESkAESsENKFAomISJZkqwoqakFFgURERDKiQCIikiVhPkzoAsWbqLWXKJCIiGSJqrZERPqplrb2UPeXSckkyjMjdlAgEREJeGP9Lg679lleW1eZ76x0YREedEuBREQk4NW1Ff6/0QokwTYSPZAoIlIIQrhbu6jd8bNEgUREJCCT4Uz6KwUSEZE4wihLhNmuEeWyjQKJiEhAb+79iaqwVLUlIiIpSRYv+nplmQKJiEiWvLy6IuN9xB1GPmIVXQokIiIZSnRbX7CqLKf5yBcFEhGRONJp3kjWFhLlhwnDoEAiIhKQjVt+X290VyAREYkjnXaIXISJKMciBRIRkQxF+SafCwokIiJZpjYSEZF+JNV7fl1Ta+f7nHfHjVgJSIFERCSOZNVVn/3tP1JO29cpkIiIBKRaDbW2vC7LOSkcCiQiInH080JGWnIWSMzsGjNbYmbVZlZuZk+Z2VEpbHe0mS00swYz22pmP7O+3nIlIlJAclkiOQ24FzgZOB1oBeaZ2ZhEG5jZSOAFYCdwAvAD4Erg8mxnVkREUjMgVwdyzn0q+NnMvgrsAU4Bnkqw2QXAUODrzrkGYIWZTQUuN7NZrq8/LioiEkfUbnz5bCMZ4R9/dw9pTgJe8YNIh7nA/sDk7GVNRPq7qPxMjUo+epLPQHIn8DawuIc0E/CqtYJ2BtaJiIRKLbDpy1nVVpCZzQJmADOcc21JksfGY0uwHDO7GLgYYNKkSZlmU0T6sTAfMuzrwSnnJRIz+w3wZeB059y6JMl30L3kMd7/N7akgnPuAefcdOfc9HHjxmWeWRHpd6wX4/8WQvVTNuU0kJjZncBX8ILIqhQ2WQycamaDA8vOArYBG8LPoYj0d9kY7qSvB5pcPkdyD/ANvNLIbjOb4L+GB9LcbGbzA5s9CtQDs83sKDM7D7gaUI8tEem3onb7y2WJ5DK8nlrzge2B1xWBNBOBQzs+OOf24JVA9gdKgXuA24FZucmyiPQ3vanaSrrPPt5GksvnSJJ+lc65i+IsWw7MzEaeREQSSmeq3cg92ZFbGmtLRCQgaqWHeEEqYjVbCiQiIvGEea/ORnVZlCiQiIgUmKiVmhRIREQylKyqKew2FFVtiYhEWMR+7BcEBRIRkTjCfFZDbSQiIv1I1Nof4olYzZYCiYhIPOkUSLJ5Y49ae0g8CiQiIllWCKWcTCiQiIhIRhRIREQC+nrDeDYokIiIxJGPponaplZ21TV3fi6rbqSxJdncf/mXlxkSRUSiqjftGWF1FZ5564vsqmtmwy3nAvCxm+ZzzIGj4xwvlMOFRiUSEZE48nGzDpZGOizbXJX7jKRJgURERDKiQCIiEke6VVzb9zTw9Dvb4+8rhPxEmdpIRETiSPeBxPPvX8yW3Q2cfdQ5FBf19dDRlUokIiIh2FrVkO8s5I0CiYhIHP19+tx0KJCIiARYlsYz2b6na4nlqWXber2vqAU5BRIRkQwF21MSPVPyu5fXd/n8/f97K5tZyikFEhERyYgCiYhIHL19IDHeZhr9V0SkH+nj9/ysUCAREclUlzaS/GUjXxRIREQCelsNlcsAErVgpUAiIpIDUeuyG6a0AomZ7WdmV5jZfWY21l92ipkdnOL2M83sSTPbambOzC5Kkn6yny72dXY6+RYRyZW+HDASSTmQmNnxwPvABcC3gJH+qrOAG1PczXBgBfBDIJ3xBM4GJgZeC9LYVkQkbWHNMdIfpFMiuQ240zl3LNAUWD4XOCWVHTjnnnHO/btz7jGgPY1jVzrndgRe3QftFxEJQW+aSIKlkHjxJ1tPy0dFOoHkeOChOMu3A/uFk52EnjCzMjNbZGZfyPKxRERCr6Dqy3PBpxNIGoB94iw/AigLJzvd1AJXAF8EzgHmA38yswvjJTazi82s1MxKy8vLs5QlEenL+nrpIRvSmY/kb8D1Zna+/9mZ2WTg18DjIefLO4BzFcDtgUWlfiP/T4Hfx0n/APAAwPTp01XBKSKSA+mUSK4AxgDlwFDgH8AaoAq4LvysJfQ6cFgOjyci0iOXwgOJfbk3V8olEudcNTDDzE4HjsMLQm865+ZlK3MJTMNrlxERiawr5yzL2r6j1qMspUBiZgPxSiBfc84toJfdb81sODDF/1gETDKzacAu59wmM7sZ+Jhz7gw//deBFuAtvF5enwG+C1zVm+OLiKSq94M2ehvOWbolxNxEW0qBxDnX4j90mGkYnA68GPj8c//1EHAR3jMih8Zscx1wENAGfAB80znXrX1ERCQM2WhrD3uXUesQkE5j+0PAd4Are3sw59xL9PCdOucuivn8EPG7HIuIZFU6bRrBlLmodSrIqi3fMOACMzsLWArUBVc6534QZsZERPIhWr/1C0M6gWQq8Kb//pCYddEKjyIiUWJ9+4HEdHptfTKbGRER6Qvi/qp24Xb/jdov97SHkTezwWZ2lJkdaWaDs5EpEZF8S6cZIlmbxatrKzPMTbSlM/rvQDP7T2A3sAxYDuw2s1v97sEiIoUvwx5R8YLK8q17Mtpn1KXTRvJr4MvAJXjPlACcCtyMF5CuCDdrIiL5E7XqoyhLJ5B8Be8ZjmcCy9aaWTnwIAokItIHZNok3h8DUDptJKOAtXGWrwVGh5MdEZG+qb099RDzxvpdWcxJ+NIJJMuAeM+K/BB4O5zsiIgUnlQeSNxa1Zjy/i5+pLTn40Ws2JNO1dZPgWf8BxIX4313JwH7A5/OQt5ERPImnzfrtjRKL1GQconEOfcycDgwB2/u9ZH++8Odc//oaVsRkUKR8TBWIcSAdKrBoiCdEgnOua3AtVnKi4hI3l37lxX+u/zdzNuiVneVRDrPkXwv3hS3ZnahmV0WbrZERApHl4mtQghAfbZqC/gRsDnO8g3Aj0PJjYiI9OlAcgCwMc7yLf46EZFutlU1sL6iLnnCPi6dtpcCiyNpBZIdeNPcxjoOqAgnOyLS15x8ywI+edtL+c5GzuRkPpKIPfaYTmP7o8BdZlYHvOQv+yRwB/CHkPMlIpJXaQ3amMKNvcDaz9OSTiC5HjgYmIs37S1AMfBn4D9CzpeISEHqw/EioXTmI2kBvmxm/wEcizckzUrn3PJsZU5EJF/CLkGsr6gNd4cRkrSNxMzOMLMvdnx2zq0BpgAPA2+Z2XNmprG2RERIPDfJ2vK+2+Eglcb2qwn0yjKzjwE3Ao/gDZtyDHpIUUQkVMkmy4qSVALJ0cDCwOfzgVedc99xzs3CG8jxs9nInIhIQXBx32bvcBGLMakEktFAWeDzKcBzgc9LgA+FmSkRkXyLWhfbKEslkGwHDgUws0F4De2LA+tHAE3hZ01EpPBErbSQC6kEkmeBW83sdLzpduuAVwLrPwqsyULeRETyJt8BoafjRy1WpdL992fAE8A8oBb4unOuObD+m8ALWcibiEhBiNqNPdeSlkiccxXOuZnAPsA+zrm/xCQ5H/hFKgczs5lm9qSZbTUzZ2YXpbDN0Wa20Mwa/O1+ZpbxjAEiIt1U1TcnT5RELtpWonYDTGdiqz3OubY4y3fFlFB6MhxYgTc9b0OyxGY2Eq+0sxM4Aa+H2JXA5anmW0QkVXsaWvKdhZRErQSU1sRWmXLOPQM8A2Bms1PY5AJgKF51WgOwwsymApeb2SxXSB2tRSTyLPBbv9c3l5DuSoV0c0tn9N98OAl4xQ8iHebizRM/OS85EpE+q7eV5rE/adeWZz4cSiH9To56IJmAV60VtDOwrgszu9jMSs2stLy8POuZE5G+q7f3cQeccfvCpOlS2U/CdRGLMVEPJND9+7QEy3HOPeCcm+6cmz5u3Ljs50xERCIfSHbQveQx3v83tqQiIhKasKq5eitqpY6eRD2QLAZONbPBgWVnAdvw5ooXEcmKsCe2Svv4BdTcntNAYmbDzWyamU3zjz3J/zzJX3+zmc0PbPIoUA/MNrOjzOw8vNGI1WNLREIXxhNqYQWAQrrD5bpEMh14y38NAX7uv+94oHEi/rhe4D27glcC2R8oBe4Bbgdm5S7LItIfFVKJIN9y/RzJS/TwUKZz7qI4y5YDM7OXKxERTxiDZuSmJBGtIBf1NhIRkZzpEkYiPGhj1CiQiIhkKBs3/UKqWlMgEREJUVi3f5VIREQKUJTGFS+gOKJAIiIST29v5P3xyQQFEhERn/Vypo9shI6eAlLUYpUCiYiIL1i11duSRWhDpISzm5xQIBGRPu9vb2/ltXWV+c5GWnoKSM+/F62hBnP6QKKISD788I9vA7DhlnN7TBehtvYeiyS76jKfEjhMKpGIiGSoPzawBymQiIjE0fteW2Edv3CCkwKJiIivt7fur/33G6HmA1IPSFEoDCmQiIhkaF1FXef70IaRTzFdewQiiQKJiEgEFVK7iwKJiKSsvKaJ1rb2jPZRVd9MY0sbABW1TbRkuL8w1TS2xF2+raohxzlJrqre67kVhXijQCIiKalvbuWEG+fxH39bkdF+pv3iBf7l3ldpam1j+q/mcfXjy0PKYebOnPVy5/uOG3R9cysn37Ig5X3k6oHEab94IZwDhUCBRERSUt/slSLmvpv5w3Art1fT0ubdKp9dsT3j/WVTg3/euZZyY3t2s5ESBRIRSUtYD+1F6uG/ODpu0OnOmhjaMPKRCBGpUSARkZSEUWWzrrw2K/tNVU1jC399a2ta26Qb8J5bsSPNLRJIuftv/gOOhkgRkbRkMmfH6bcv7LafXP7yvvqJ5Tz9znamjB/OUR8aldI26Z7vr59b1YucdZf/8JA6lUhEJCV7b/jhVEr1dsj2TGz3e1919BpLRT7yCdHojZUqBRIRSY1/YwtrFsGotwF0VhlFvDEnCgFHgURE8irsG+Gc0s3cNX913HXpNpznU6qBNgoBWW0kIpKSsG9XHQEk7P1e+dg7APzgjMPiHDP1o+X79hyFkkaqVCIRkbSE9Zu+gO6TeZHq9xOFgKNAIiIpydoNKwI3wihKtfQUha8v54HEzC4zs/Vm1mhmS83s1B7SnmZmLs7riFzmWUT2Cq2xPQc/pdeV1zL56qe7Lf/C/YuZ8evkw55MvvppLnlkaTay1qmspjGr+8+FnAYSM/sScCdwE3As8CrwrJlNSrLpkcDEwCt+S5qIZE22GnWz2Vj81qaqhOu27E4yEKOfrcVZnut9bVld3OVRqLJKVa5LJJcDs51zv3POrXTOfR/YDlyaZLsy59yOwCs/g9+ISGjPVXTcJwvphhlFUfj+chZIzKwEOB54PmbV88DJSTYvNbPtZjbfzD6ZlQyKSI9ib1jrymspr2kKbX/ZkEk1XK661SbKY2Vdc9Jt29odSzfuDjlH6ctliWQsUAzEDh26E5iQYJuO0srngfOA94H5ZjYzXmIzu9jMSs2stLy8PJxci0gXHTe+029fyAk3zst4fxH4QZ1XiQLq/7tnUdJt75q/mnkrMx+NOVP5eI4k9muzOMu8hM69jxc8Oiw2s8nAFcDLcdI/ADwAMH369P7+9ykSqnAHSCEnEST2Jt3Xbgrv76jJdxaA3JZIKoA2upc+xtO9lNKT14HuTxqJSFZ19LIK6+nwKDyRLeHIWSBxzjUDS4GzYladhdd7K1XT8Kq8RCSH0m3TWLJhF397O/mQ7R0BatWOah55bWNvskZVfTOfu2dRtyHcY2NeT724Yu2s7n37T3+T66qtWcAjZvYGsAi4BNgfuB/AzB4GcM59zf/8I2AD8C5QAlwI/D+8NhMRibDz71/c4/rYIVLOvuMVAL768YPSPtb1T77Lss1VXPL7rs98ZNKgH4VG7GSiMnRYTgOJc+5PZrYvcB3e8yArgHOccx0/Q2KfJykBbgM+BDTgBZRznXPP5CjLIpIlYVZs5Ws6XPHkvLHdOXcvcG+CdafFfL4VuDUH2RKRJLLVXTcKz0HkU19oK9LovyKSko4bXm+rU2JnDnxldfwu+ufc+Qrvba/m/guP5+XV5fx92TZa2x2LrzmDUUMG9u7gfVRtU2u+swAokIhIijItOdz30toun6+Ysyxuuve2VwNw0zMr2bSrvnP5iq17OGXK2Ph5yyxreZXJSAFrympDzEnvafRfEUlJ53MkoQ3amF769j5aB6aqLRHp82oaWygush5H63XOUVHbzKCBRQwsKmJISXHS/SYLDLHDr7S1d09f39wadznA5l311DX3XPWzp76FducYNmgAlXW57+6b6ci/UYmtCiQi0qOjb3iefYYO5LFLvSHx4lXFPPDyOm5+1msDGTdiEEuuPTPpfhPc/zs1tHTtiRXvpnniTfOpaWzlrI/s123dqbe+mDQPx/zCG/rvzKnjmbeyLGn6sH3sxvn84PQpvd4+KqUZVW2JSFK761sCT7Z3X//S+3sbzjMZyLEn8UoeNY1eiSPTX+b5CCIdVmyrztuxw6JAIiIp6bhZ5+sZuL7aRtIXKJCI9GFrymp5PWZipp3VjSxY1XV4O+ccT7y5hcaWxA/2pXMbT3f2w6ffST7q0XMrdlBZ2/eGLcnFTJHZpkAi0oedOWshX3rgtS7Lzrv3Vb45u7TLshffL+PyPy/jtrnvk0hniSSFblsvvJfe0ObfffTNpGmeeGsr33yoNGm6QpNJGIlKDFIgEelntlZ5U8y2B9ocqhu8toayHto30mnY3dPQ0svc9Wxz4LkSic7zMwokIv1UW5yfsz0VNnpqI4kNMtn6pZw4e1G5paYvIuMuZkSBRMTnnOPf/7KcN9bvyndWOm2qrGfy1U9zi9+1dvmWPVzw4Gt85+FS6mOekbjur8tZvLYy3m7iOvYXL1Dd2LXk8Le3t7Gpcu+v/vcCPYp6Cg6vrcvNd1ZZ18yrayr46WPLmPV84mq4QvLi+72fzTVbPeTSpUAi4nMOHn19E1/8r56HP8+l659cAcD9C73hRb710BIWrankhfd28vy7Xdshfv/aJr78u9e67SOR2qZWHivdAnQtidzw1Lud7y/9w95h2dOp2srm8w1fefB1/ly6hbsWrMnaMSQ9CiQivihWjhTF1DUFP2frZp2oF1Hn4hTqYqLSCCy5oUAi4otiN8zYNotEbRhh5j343F+83aZSp5/rbzKCl65f0RApIr5kQ3bkyj/9ZiHNre28dOUnu3W17VIi6eGG/4P/e4snl23r/Dz56qd7POYd81bv3Zef/sAxQ9i8q6FzeXvnk+3JQ8k1TyxPmiZM81fl78l0USAR6RSVcYs+2Ll3aPBUe/TE5jwYRFKxvqJu7778gBEMIt7ytHYp/YiqtkR8UbxRdmsjSfA/NszhQxLtKo0mEulnFEj6EeccSzfu6lV9+uZd9ezYk9mQ11FWXtPU5Vd5VAQDxztbqmhtS9IQDjyzPPlwIx1eX1/Jiq17uu4rQcms4yHD1TGTKb3XBwYdlMyoaqsfmVO6hZ8+/g73XnAc5xw9Ma1tO4bk3nDLudnIWt59/Ob5Cee1yKfgkO2f/e2iLuu6tJEEbv6X/SH5cCMd5r67k7kx3Yjb2+On/fr/vBF3+Tl3vZLy8aRvUomkH1lb4f2S3FipYSZiRTGIACnXI4VZLZdKW1FLW4JoI/2SAolIhKXc2B5iIEklpsZOOiX9m6q2hAdfWcfK7TU8/uYWHr/0ZMzgD69t4vE3tzD7GycwasjAUI/nnOO+hWv5l2M/xMRRQ3q9n+bWdu5esJpLTzuUoSX5/1OeU7qZwyeM4KMHjE572zVlNby6tpKvnTS5c9n6ijr+3sPw6j+Zs4yfzFkGwDEHpn/MRFIZIuajNzwf2vGk8OX/f5/kTpxfmjWNLfzq6ZWdnz9/36td1l/0v0tCz8aGynpufe59nluxgye/N6PX+/lT6WbuXrCGtnbHT88+IsQc9s6Vj70D9K4d6bO/XUR9cxtf/fhBncv+9YHUh2pZtrkq7WOKhEVVW5JzxX6X1l11zRntp82vp69vLvxqlo5zaA60PdQ1Ff55SbiOmxReyTNMCiT9SZwK90Q9dLKpo0trU2tmBy8u8k6oNR8nkSXNge+kSA9sSIwBxdG8ZVuuxxcys8uAK4GJwLvAj5xzCfsPmtkngFnAkcA24Fbn3P3JjjN9+nRXWpr+bGrlNU2cfcfLXHX2EXzxhAPT3r4n9y9cy4KVZfz5kpMAeG7Fdi75/ZtMGT+cNYG++St+/imGDwq/1vHnT73L/y7a0Pn5jWvPYEBREcf98oW093XEhBF85pj9mTFlLJ+7Z1HyDXpw5tT9GD10II8t3cL5xx/AjMPGMuuFD3jxJ6fx1uaqbtVtF5w4iT+8vimjY6br2nOmcuMzK5MnFMmic4+eyNMpPifU2676ZrbUOTc9nW1yGt7M7EvAncBNwLHAq8CzZjYpQfqDgWf8dMcCNwN3m9nns5XHoSXFVNY1U9WQWbVLPLc8u4o3NuxtyLx/4TqALkEEsveAV2xV0ourynr9a37Vjhr+c+77zHrhg4zzNW/lTh5b6g1nPmfpFq56/B02VtZT19zKDU++2y19roMIoCASkmMOHM2HRnftYDF536F5yk16SoqLuOjkyQwrKebgscO6rf/ZP3+EYw4YFeoxYzu63PDZI7n2nKn800f261z2qSP3i92MF348M9R8JJPrxvbLgdnOud/5n79vZmcDlwLXxEl/CbDNOfd9//NKMzsRuAJ4PBsZHFpSjBnUNrYmT9xLzjnMLGHVTnOGVT6pam5tz7hqq64p/O+ppLiIxpZ26praGFis+p2oeffnn+LI6+emvd3jl57E8QeNAfYOIjloQBEvXfnJLumSDTCZK3///gz++e5/dH7+4MZPA97NPJFvzji483265zGw2GgJjFxw1dlHcOlphwIw5d+fobXdMXLIAL4z8xC+M/OQLtt+7rf/YNmWvSMUHLbfiLSOnamcBRIzKwGOB26LWfU8cHKCzU7y1wfNBb5uZgOdc6FPDG1mDB80gPWV9VnrCbNkw24GDSiirDr+kCOrdlQzYnD4l2b1zq4ln9VltUwctSdB6tS8v6Mmo+3jqfaD+NKNu/XwZASVDIhfkTFkYHHaz5fEjiXWn3mjGOwNJMMD94COsdSKE3xfqYzInE25LJGMBYqBnTHLdwJnJthmAjAvTvoB/v66VBaa2cXAxQCTJsWtLUvJuOGDeGrZNp5KcwTVVCWbgS/YHTebHl68kYcXb8xoHzVZKJF0+O6jqQ/1IbkzIEEvgH86cj/+9nbi/zNjhw/qfH/a4eN46f1yPnnEuNDzF5Z9h5dktP0hY4exLo3x2z5x+DheeG/v7fGICXtLFacdPp4Fq8oSBt6PHTyGt/PYBTxnje1mtj+wFZgZbFw3s+uBLzvnuj0IYGYfAI84534ZWPYJ4CVgonNuR6Lj9baxHWBDRR3rKmqTJ0xTc6ujuqGFsSP2/oFW1jYzeGAxb2+uYsywEoqLjA/vNzz0Y3dYunF3Z73rlPHeccprmmhuc1TUNDF14kiKi4zymibKa5ooMhg4oIjK2iaKzBhQbBy07zAGFBklA4oYWlLM4rWVjBw8kPUVdew7vITDxo+gzTkqa5sYNKCYJRt2MfPD42hubWff4SW8tamKscNLOHDMUFbtqGHqxJFJSx6XAAAM0ElEQVSAV504pKSIEYMGUlbTxIRR3o3nzY1VfGT/kby4qoxhgwZwypSxlNc00e4ctU2tlBQX0dzWztbdDQwoNv6xuoLvnT6FkYMHUjKgiGVbqmhubaeqvoWxw0s4YfIYFq+rZOKowZgZ7e2OEYMHMmLwADZW1jGwuIh2B02tbRQXGRsr6zllyr58sLOWIoOy6iYOHjeMxpZ2RgwewK66ZgYPKGL44IE0tbbxzuY9TNp3KCOHDGR7VQMOqG9q5egDRlPd0MLAAUW8u3UPY4aVcOi44VTWNVHX1IbD66k1rGQAbc7R1u6oqG1i4qjBTJ88hu1VjZwweR+Ki4xnVuygpNi7Ttv2NDJkYDHjRwyiyIwp44fjcBy07zDe3uTdXEYNGUh1YwtlNU0ce+BodtU189bmKg7YZwi76pqZduBoKmubqW9upbapjT0NLRw3aTQnHrIv7e2Od7dVM2hgEQfsM4SJo4bw1qbd7NjTyOETRrBsSxXHHDCa8SMH886WKqobWqiqb+HEQ/blqWXb+NjBYyguMk6YPKbz77CptY1X11Ry8pR9GTSguMvfaFlNI00t7WzZ3cCmXXUctt8Iahpbqapv5tTDxrGnoYUdexopq2nEzBg6sJglG3cxZdxwRg4ZyKABRRw+YYR/HR176lvYZ1gJa8tq2b6nkZIBRWzZXc+B+wylqqGFg8cOo7XNUdfcysFjh7HfiMFUN7Zw4JihLN24m8raJqaMH84h49L7f1nT2EJ1YytFBsu37GHapNHUNrZiZqwtq6WmqYXioiI+8eFx7K5rZsKowdQ2teIc7K5v5sOB6qnGljZ2Vjdy0L7d22YAWtva2VBZz7vb9nDk/qM6/2/3Rm8a23MZSEqAerygMSew/B7gKOfcJ+Js8zKw3Dn33cCy84FHgaE9VW1lEkhERPqrSPfacs41A0uBs2JWnYXXKyuexXSv9joLKM1G+4iIiKQv10+3zAIuMrNvm9lUM7sT2B+4H8DMHjazhwPp7wcOMLM7/PTfBi6ie4O9iIjkSU67/zrn/mRm+wLX4T2QuAI4xznX0eI7KSb9ejM7B/gNXhfhbcAPnHNZ6forIiLpy/mgjc65e4F7E6w7Lc6yhcBxWc6WiIj0UjQHbhERkYKhQCIiIhlRIBERkYwokIiISEZyPox8rphZOZDJ+B9jgYqQspNvOpfo6kvno3OJrnTO5yDnXFpj1/TZQJIpMytN9+nOqNK5RFdfOh+dS3Rl+3xUtSUiIhlRIBERkYwokCT2QL4zECKdS3T1pfPRuURXVs9HbSQiIpIRlUhERCQjCiQiIpIRBZIYZnaZma03s0YzW2pmp+Y7T7HM7AYzczGvHYH15qfZZmYNZvaSmR0Zs499zOwRM9vjvx4xs9E5yPtMM3vSzLb6+b4oZn0oeTezo81sob+PrWb2M8vCxNYpnM/sONfqtZg0g8zsbjOrMLM6f38HxKSZZGZP+esrzOwuf7K4sM7jGjNbYmbVZlbuH+uomDQFc21SPJ9CuTbfNbN3/HOpNrPFZnZuYH3+r4tzTi//BXwJaAG+A0wF7gZqgUn5zltMPm8AVuHNad/xGhdYfxVQA3weOAr4M94Q/CMCaZ4F3gVOBk7y3z+Vg7yfA9wEfAFvxsyLYtZnnHdgJLDD3/Yof181wE/ycD6zgRdirtWYmDT3+ed4Ft5I1y8BbwPF/vpiYLm//Dg/3Tbg7hDPYy7wDf/7Ohr4i/8djgmkKZhrk+L5FMq1+RzwaWAK8GHgRrz71Eejcl2yetMotBfwOvC7mGWrgZvznbeYPN0ArEiwzoDtwLWBZUP8P4p/8z9PBRxwSiDNDH/Z4Tk8j1oCN96w8o43d001MCSQ5jpgK34Hk1ycj79sNvD3HrYZBTQDFwSWHQi0A5/yP3/a/3xgIM2FQCMwMkvnMhxoAz7TR65Nl/Mp5GvjH2MX8G9RuS6q2vL5RdHjgedjVj2PF8Wj5hC/+LnezP5oZof4yw/G+2XVeR7OuQbgZfaex0l4N73gFMeLgDrye65h5f0k4BV/2w5z8WbjnJyNjCcxw8zKzOwDM/udmY0PrDseGEjXc94MrKTr+az0l3eYCwzyt8+GEXhV37v9z4V+bWLPp0NBXRszKzazf8ULjK8SkeuiQLLXWLxi6s6Y5TvxLlSUvI435fCn8arhJgCvmjf7ZEdeezqPCUC58392APjvy8jvuYaV9wkJ9hE8Rq48B3wNOAP4CfAxYIGZDQrkp43u4yDFnnPs+VT422XrfO7Eq8JZHMhDR76CCuXaxJ4PFNC18dsvaoEmvCnI/8U5t5yIXJecz5BYAGIfrLE4y/LKOfds8LPfQLgO+DrQ0ViY7DzinVNUzjWMvMfbR6Jts8Y598fAx+VmthRvMNFzgSd62DSVc+5pea+Z2Sy8qo8Zzrm2JMeL/LVJdD4Fdm3eB6YBo/HaLx4ys9N6OFZOr4tKJHsl+hUxnu6ROlKcc7V4jWeH4TWYQc/nsQMYH+yR4b8fR37PNay870iwD8jztXTObQO24F0r8PJajFciDoo959jzSVSCzoiZ/Qb4MnC6c25dYFVBXpsezqebKF8b51yzc26Nc67UOXcNXunqx0TkuiiQ+JxzzcBSvF4XQWfRtW4xcsxsMHAEXqPberw/irNi1p/K3vNYjFfHelJgNycBw8jvuYaV98XAqf62HTp602zIRsZTZWZjgQ/hXSvw/uZa6HrOB+A1kAbPZ2pMt9Oz8Ko5loaYtzuBr+DddFfFrC64a5PkfOKlj+y1iaMIrx0mGtclW70KCvGF1/23Gfg23h/LnXiNVAflO28x+bwN+AReQ9uJwN/xelwc5K+/yv98Hl5Xvj8SvzvgcuDj/h/VcnLT/Xc4XhF9Gl532Z/57yeFlXe83jY7/G2P8vdVTXa6/yY8H3/dbX4eJwOn+f9ht8Scz314vWPOBI4FXiR+F9MF/voz/fRhdjG9x/+OTqdrd9jhgTQFc22SnU+BXZtb8ALDZLyuzDfj9RT7dFSuS1ZvGoX4Ai7Di8Advyhm5jtPcfLY8YfS7P/RPg58JLDe8LoIb8frhrgQOCpmH2OA3/t/LNX++9E5yPtpeHWusa/ZYebd/w/3sr+P7cD1ZKF7aU/ng9cNcy5eo2YzXv37bAJdRf19DMZ7ZqkSLxg9FSfNJLwfDPV+uruBQSGeR7xzcMANYf9d5eLaJDufArs2s/38Nfn5nYff/Tgq10WDNoqISEbURiIiIhlRIBERkYwokIiISEYUSEREJCMKJCIikhEFEhERyYgCiUjI/AmSvpDF/U/3jzE5W8cQSYcCiUhAglnzus2cl8REvAfXRPoFjf4r0t084Ksxy5pT3dg5tyN5KpG+QyUSke6anHM7Yl67oLPa6ntm9rSZ1ZvZRjO7MLhxbNWWP/f1RjNrMrMdZvZwYN0gM7vDzHaaWaOZvWZmM2L2d7aZrfLXv4I33SoxaU7259uu9yc8u8/MRob+zYjEoUAikr6fA0/iDc74APCwmU2Pl9DMPg9cgTeG22HAPwNvBJLcijdY6DfxBv1bDjxnZhP97Q8E/oo3t/g0vHGcbo05xtF4M+Q9CRyDN+DeNOB/Mj9VkeQ01pZIgJnNZu+c20H3OOeuMjMHPOic+05gm3nADufchf5nB5zvnHvMzC7Hm1v7KOdcS8yxhuFN/fpt59zD/rJi4APg/5xz15nZTcAX8ObWdn6a64BfAgc75zb4JZwW59y3AvueBrwF7OecKwvn2xGJT20kIt29DFwcs6wq8H5xzLrFeLPqxTMH+CGw3szm4k3v+qRzrgk4FG9O8EUdiZ1zbWa2GPiIv2gq8Jrr+osv9vjHA1PM7EuBZR2TGB2KN2KsSNYokIh0V++cWxPGjpxzm83scLx5wc8EbgeuN7MT6Xkq045lFmddrCLgQeA3cdZtTS/HIulTG4lI+j4e5/PKRImdc43Ouaedcz8GTgCOBE4B1uD1ButsXPertk4C3vMXvQecGJwmNc7x3wSOdN5UrLGvhl6cn0haVCIR6W6QmcXOX93mnCv3359nZkuAl/DaL87Am6myGzO7CO//2et4s21+CW/61tXOuTozuw+4xcwq8KZN/TGwH3Cvv4v7gZ8Ad5jZvXiTD10Sc5hfA6+Z2f3AfwE1eFMvf8Y592/pn75IehRIRLo7k73zdnfYCnTMy30D8HngLqAc+IZzbkmCfVXhTYV6G157yHvAec659f76q/x//xcYjddAfrZzbjuAc26TmZ0HzMJrtF8KXI03wx1+mnfMbCbwK7zZ8YqBdcBf0j1xkd5Qry2RNAR7ZOU7LyJRoTYSERHJiAKJiIhkRFVbIiKSEZVIREQkIwokIiKSEQUSERHJiAKJiIhkRIFEREQyokAiIiIZ+f+k5kQ5Ngqq4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f555d450518>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solve in 1 episodes. Average score: 2.65\n"
     ]
    }
   ],
   "source": [
    "rand_seed = 0\n",
    "agent = Agent(config=config,\n",
    "              state_size=state_size, \n",
    "              action_size=action_size, \n",
    "              num_agents=num_agents, \n",
    "              random_seed=rand_seed,\n",
    "              device=torch.device('cpu'),\n",
    "              actor_trained_weight_filename=\"checkpoint_actor.pth\", \n",
    "              critic_trained_weight_filename=\"checkpoint_critic.pth\")\n",
    "\n",
    "scores_test = ddpg(agent, train_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "MADDPG is a efficiently working network for such two agent problem. Some further tricks can be investigated using different environments to see what could be fallbacks of this network to improve it. Without doing such a research we could better train it. Training duration is long, high number of episode is required. Weights could be cleverly initialized like transfer learning so convergence can be fasten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
